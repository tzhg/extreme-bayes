	%	 In the case $\xi=0$,
	%	\begin{align*}
	%	\lim_{\xi\to 0} \det J(\mu,\sigma,\xi) &=\frac{\sigma}{2}\sum_{i=1}^3s^2_i(s_{i+2}-s_{i+1})\propto \sigma\,.
	%	\end{align*}
	
	% LOG MARGINALS
	
	%	\begin{figure}
	%		\centering
	%		\includegraphics[width=0.9\linewidth]{plots/prior-pdf-log.pdf}
	%		\caption{Log prior marginals of $\theta$ using method 1 (blue) and method 3 (orange)}
	%		\label{fig:prior-pdf-log}
	%	\end{figure}
	
	
	
	
	%	\begin{figure}
	%		\centering
	%		\includegraphics[width=0.49\linewidth]{plots/prior-0-contours-log.pdf}
	%		\includegraphics[width=0.49\linewidth]{plots/prior-1-contours-log.pdf}
	%		\caption{Bivariate log prior marginals of $(\mu, \sigma, \xi)$ using method 1 (left) and 3 (right)}
	%		\label{fig:prior-contours-log}
	%	\end{figure}
	
	
	
	
	
	
	% PRIOR METROPOLIS
	
%We sampled from $\pi_\theta^{QD}$ and $\pi_\theta^{ME}$ using a Metropolis algorithm. The parameters and results are listed in Table~\ref{table:prior-0} and Table~\ref{table:prior-1}. We reparametrised the density to $\mu, \log(\sigma), \xi$ to allow us to use Normal proposals for each parameter. In Fig.~\ref{fig:prior-return-level}, the mean return level is plotted using our samples, with 95\% credibility intervals and empirical quantiles.
	
%	\begin{table*}
%		\centering
%		\renewcommand{\arraystretch}{1.2}
%		\metro{$\mu^{\text{new}}\sim{\cal N}(\mu^{\text{old}}, 20^2)$,\quad$\log\sigma^{\text{new}}\sim{\cal N}(\log\sigma^{\text{old}}, 0.4^2)$,\quad$\xi^{\text{new}}\sim{\cal N}(\xi^{\text{old}}, 0.1^2)$}{$50$,\quad$3$,\quad$0.5$}{$100,\!000$ (after burn-in of $2,\!000$)}{plots/prior-0-trace.pdf}{plots/prior-0-hist.pdf}{$0.473$,\quad$0.368$,\quad$0.283$}{$40.567$,\quad$5.177$,\quad$0.469$}
%		\caption{Metropolis algorithm for $\pi_\theta^{QD}$}
%		\label{table:prior-0}
%	\end{table*}
%	
%	\begin{table*}
%		\centering
%		\renewcommand{\arraystretch}{1.2}
%		\metro{$\mu^{\text{new}}\sim{\cal N}(\mu^{\text{old}}, 20^2)$,\quad$\log\sigma^{\text{new}}\sim{\cal N}(\log\sigma^{\text{old}}, 0.4^2)$,\quad$\xi^{\text{new}}\sim{\cal N}(\xi^{\text{old}}, 0.1^2)$}{$50$,\quad$3$,\quad$0.5$}{$100,\!000$ (after burn-in of $2,\!000$)}{plots/prior-1-trace.pdf}{plots/prior-1-hist.pdf}{$0.425$,\quad$0.346$,\quad$0.318$}{$34.452$,\quad$8.510$,\quad$0.473$}
%		\caption{Metropolis algorithm for $\pi_\theta^{ME}$}
%		\label{table:prior-1}
%	\end{table*}
%	
%	\begin{figure}
%		\centering
%		\includegraphics[width=0.6\linewidth]{plots/prior-return-level.pdf}
%		\caption{Mean return level with 95\% credibility intervals estimated using $\pi_\theta^{QD}$ (blue) and $\pi_\theta^{ME}$ (orange), and empirical quantiles (dots)}
%		\label{fig:prior-return-level}
%	\end{figure}


% VARYING THRESHOLDS

	%\begin{figure}
%\centering
%\includegraphics[width=\linewidth]{plots/u-post.pdf}
%\caption{Posterior marginals for $u=40$ (red), 45 (orange), 50 (yellow), 55 (green), 60 (cyan), 65 (blue), 70 (purple) using method 1 prior}
%\label{u-post}
%\end{figure}

	%\begin{table*}
%	\centering
%	\renewcommand{\arraystretch}{1.2}
%	\begin{tabular}{@{}ccccc@{}}
%		\toprule[0.1em]
%		u&Number of exceedances of $u$&$\mu$&$\sigma$&$\xi$\\
%		\midrule[0.1em]
%		40&189&50.479&9.886&0.258\\
%		45&106&50.156&8.712&0.288\\
%		50&60&50.469&7.517&0.32\\
%		55&38&52.708&5.259&0.39\\
%		60&21&54.918&3.964&0.447\\
%		65&12&58.246&2.777&0.523\\
%		70&4&41.889&5.731&0.413\\
%		\bottomrule[0.1em]
%	\end{tabular}
%	\caption{MCMC posterior means of $\mu,\sigma,\xi$}
%	\label{table-u-post-means}
%\end{table*}

%\begin{figure}
%	\centering
%	\includegraphics[width=\linewidth]{plots/u-estimates.pdf}
%	\caption{Posterior mean estimates and 95\% credibility intervals of $\theta$ for varying thresholds with method 1 prior}
%	\label{fig:u-estimates}
%\end{figure}


% MARG


%\begin{figure}
%	\centering
%	\includegraphics[width=0.5\linewidth]{plots/q-pdf.pdf}
%	\caption{Univariate marginal distributions of $\pi_q^{\text{QD}}$ (blue) and $\pi_q^{\text{ME}}$ (orange)}
%	\label{fig:q-pdf}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\includegraphics[width=0.49\linewidth]{plots/q-0-contours.pdf}
%	\includegraphics[width=0.49\linewidth]{plots/q-1-contours.pdf}
%	\caption{Bivariate marginal distributions of $\pi_q^{\text{QD}}$ (left) and $\pi_q^{\text{ME}}$ (right)}
%	\label{fig:q-contours}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\includegraphics[width=0.9\linewidth]{plots/prior-pdf.pdf}
%	\caption{Univariate marginal distributions of $\pi_\theta^{\text{QD}}$ (blue) and $\pi_\theta^{\text{ME}}$ (orange)}
%	\label{fig:prior-pdf}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\includegraphics[width=0.49\linewidth]{plots/prior-0-contours.pdf}
%	\includegraphics[width=0.49\linewidth]{plots/prior-1-contours.pdf}
%	\caption{Bivariate marginal distributions of $\pi_\theta^{\text{QD}}$ (left) and $\pi_\theta^{\text{ME}}$ (right)}
%	\label{fig:prior-contours}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\includegraphics[width=0.9\linewidth]{plots/post-pdf.pdf}
%	\caption{Univariate marginal distributions of $\pi_{\theta\mid\mathbf{x}^{\text{G}}}^{\text{QD}}$ (blue) and $\pi_{\theta\mid\mathbf{x}^{\text{G}}}^{\text{ME}}$ (orange)}
%	\label{fig:post-pdf}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\includegraphics[width=0.49\linewidth]{plots/post-0-contours.pdf}
%	\includegraphics[width=0.49\linewidth]{plots/post-1-contours.pdf}
%	\caption{Bivariate marginal distributions of $\pi_{\theta\mid\mathbf{x}^{\text{G}}}^{\text{QD}}$ (left) and $\pi_{\theta\mid\mathbf{x}^{\text{G}}}^{\text{ME}}$ (right)}
%	\label{fig:post-contours}
%\end{figure}


%%% RETURN TABLE


%\begin{table*}
%	\centering
%	\renewcommand{\arraystretch}{1.2}
%	\begin{tabular}{@{}cccc@{}}
%		\toprule[0.1em]
%		&$r=10$&$r=10^2$&$r=10^3$\\
%		\midrule[0.1em]
%		$\pi_{\theta\mid\mathbf{x}^{\text{GP}}}^{\text{QD}}$&$11\,(11,11)$&$11\,(111,111)$&$11\,(111,111)$\\
%		$\pi_{\theta\mid\mathbf{x}^{\text{GP}}}^{\text{ME}}$&$11\,(11,11)$&$11\,(111,111)$&$11\,(111,111)$\\
%		$\pi_{\theta\mid\mathbf{x}^{\text{GP}}}^{\text{U}}$&$11\,(11,11)$&$11\,(111,111)$&$11\,(111,111)$\\
%		\bottomrule[0.1em]
%	\end{tabular}
%	\caption{xxx}
%	\label{table:xxx}
%\end{table*}




%%%% The transformation from quantiles to GEV parameters

%
\subsection{The transformation from quantiles to GEV parameters}
\label{section:transformation}
%

%
Recall that
%
\begin{align*}
s_i = -\log(-\log(1 - p_i)) \,, \quad i = 1, 2, 3 
\end{align*}
%
and
%
\begin{align}
q_i = \mu + \sigma \frac{\exp(s_i \xi) - 1}{\xi} \,, \quad i = 1, 2, 3 \,.
\label{eq:g_r}
\end{align}
%
We will invert the transformation
%
\begin{align*}
g \colon \Theta &\to {\cal Q}\\
(\mu, \sigma, \xi) &\mapsto (q_{1}, q_{2}, q_{3}) \,.
\end{align*}
%
Rearranging (\ref{eq:g_r}) for $i = 1, 2$, we get
%
\begin{align*}
\sigma = \frac{\xi(q_i - \mu)}{\exp(s_i \xi) - 1} \quad
\text{and} \quad \mu = q_i - \sigma \frac{\exp(s_i \xi) - 1}{\xi} \,.
\end{align*}
%
Isolating $\mu$,
%
\begin{align*}
\frac{\xi(q_1 - \mu)}{\exp(s_1 \xi) - 1}
&= \frac{\xi(q_2 - \mu)}{\exp(s_2 \xi) - 1}\\
\iff (q_1 - \mu)(\exp(s_2 \xi) - 1) &= (q_2 - \mu)(\exp(s_1 \xi) - 1)\\
\iff q_1 (\exp(s_2 \xi) - 1) - \mu(\exp(s_2 \xi) - 1)
&= q_2 (\exp(s_1 \xi) - 1) - \mu (\exp(s_1 \xi) - 1)\\
\iff \mu(\exp(s_1 \xi) - \exp(s_2 \xi))
&= q_2 (\exp(s_1 \xi) - 1) - q_1 (\exp(s_2 \xi) - 1)\\
\iff \mu &= \frac{q_2 (\exp(s_1 \xi) - 1) - q_1 (\exp(s_2 \xi) - 1)}
{\exp(s_1 \xi) - \exp(s_2 \xi)} \,.
\end{align*}
%
Isolating $\sigma$,
%
\begin{align*}
q_1 - \sigma \frac{\exp(s_1 \xi) - 1}{\xi}
&= q_2 - \sigma \frac{\exp(s_2 \xi) - 1}{\xi}\\
\iff q_1 - q_2 &= \sigma \frac{\exp(s_1 \xi) - \exp(s_2 \xi)}{\xi}\\
\iff \sigma &= \frac{\xi (q_1 - q_2)}{\exp(s_1 \xi) - \exp(s_2 \xi)} \,.
\end{align*}
%
Since $q_1 < q_2$ and $s_1 < s_2$,
we have that $\xi > 0 \iff \exp(s_1 \xi)<\exp(s_2 \xi)$, and therefore
%
\begin{align*}
\frac{\xi(q_1 - q_2)}{\exp(s_1 \xi) - \exp(s_2 \xi)} > 0 \,.
\end{align*}
%
Therefore once we calculate $\xi$, we can calculate $\mu$ and $\sigma$
using the above formulae.
Substituting $\mu$ and $\sigma$ into (\ref{eq:g_r}) for $i = 3$, we get
%
\begin{align*}
q_3 &= \frac{q_2 (\exp(s_1 \xi) - 1) - q_1 (\exp(s_2 \xi) - 1)}
{\exp(s_1 \xi) - \exp(s_2 \xi)} + \frac{\xi (q_1 - q_2)}
{\exp(s_1 \xi) - \exp(s_2 \xi)} \frac{\exp(s_3 \xi) - 1}{\xi}\\
&= \frac{q_2 (\exp(s_1 \xi) - 1) - q_1 (\exp(s_2 \xi) - 1)
	+ (q_1 - q_2)(\exp(s_3 \xi) - 1)}{\exp(s_1 \xi) - \exp(s_2 \xi)}\\
&= \frac{q_2 \exp(s_1 \xi) - q_2 - q_1 \exp(s_2 \xi) + q_1 + (q_1 - q_2)
	\exp(s_3 \xi) - q_1 + q_2}{\exp(s_1 \xi) - \exp(s_2 \xi)}\\
&= \frac{q_2 \exp(s_1 \xi) - q_1 \exp(s_2 \xi) + (q_1 - q_2) \exp(s_3 \xi)}
{\exp(s_1 \xi) - \exp(s_2 \xi)}
\end{align*}
%
\begin{align*}
&\iff \frac{q_2 \exp(s_1 \xi) - q_1 \exp(s_2 \xi) + (q_1 - q_2) \exp(s_3 \xi)
	- q_3 (\exp(s_1 \xi) - \exp(s_2 \xi))}{\exp(s_1 \xi) - \exp(s_2 \xi)}=0\\
&\iff \underbrace{\frac{(q_2 - q_3) \exp(s_1 \xi) + (q_3 - q_1) \exp(s_2 \xi)
		+ (q_1 - q_2) \exp(s_3 \xi)}{\exp(s_1 \xi) - \exp(s_2 \xi)}}
_{\eqqcolon h(\xi)} = 0 \,.
\end{align*}
%

%
We will now study the behaviour of $h$.
As $s_1 < s_2 < s_3$,
%
\begin{align*}
\frac{\exp(s_2 \xi)}{\exp(s_1 \xi)} = \exp((s_2 - s_1) \xi) \to 0
\quad \text{as} \quad \xi \to -\infty \,,
\end{align*}
%
and
%
\begin{align*}
\frac{\exp(s_3 \xi)}{\exp(s_1 \xi)} = \exp((s_3 - s_1) \xi) \to 0
\quad \text{as} \quad \xi \to -\infty \,.
\end{align*}
%
Therefore
%
\begin{align*}
h(\xi) = \frac{(q_2 - q_3) + (q_3 - q_1)
	\frac{\exp(s_2 \xi)}{\exp(s_1 \xi)}
	+ (q_1 - q_2)\frac{\exp(s_3 \xi)}{\exp(s_1 \xi)}}
{1 - \frac{\exp(s_2 \xi)}{\exp(s_1 \xi)}} \to q_2 - q_1 < 0
\quad \text{as} \quad \xi \to - \infty \,,
\end{align*}
%
and similarly,
%
\begin{align*}
h(\xi)= \frac{(q_2 - q_3)\frac{\exp(s_1 \xi)}{\exp(s_3 \xi)}
	+ (q_3 - q_1) \frac{\exp(s_2 \xi)}{\exp(s_3 \xi)} + (q_1 - q_2)}
{\frac{\exp(s_1 \xi)}{\exp(s_3 \xi)} - \frac{\exp(s_2 \xi)}
	{\exp(s_3 \xi)}} \to \infty \quad \text{as} \quad \xi \to \infty \,.
\end{align*}
%
For all $\delta > 0$,
%
\begin{align*}
\exp(s_1 \delta) < \exp(s_2 \delta) < \exp(s_3 \delta) \,,
\end{align*}
%
and so
%
\begin{align*}
h(\xi + \delta) &= \frac{(q_2 - q_3) \exp(s_1 (\xi + \delta)) + (q_3 - q_1)
	\exp(s_2 (\xi + \delta)) + (q_1 - q_2) \exp(s_3 (\xi + \delta))}
{\exp(s_1 (\xi + \delta)) - \exp(s_2 (\xi + \delta))}\\
&= \frac{(q_2 - q_3) \exp(s_1 \xi) \exp(s_1 \delta)
	+ (q_3 - q_1) \exp(s_2 \xi) \exp(s_2 \delta)
	+ (q_1 - q_2) \exp(s_3 \xi) \exp(s_3 \xi)}
{\exp(s_1 \xi) \exp(s_1 \delta)
	- \exp(s_2 \xi) \exp(s_2 \delta)}\\
&\geq \frac{(q_2 - q_3) \exp(s_1 \xi) \exp(s_3 \delta)
	+ (q_3 - q_1) \exp(s_2 \xi) \exp(s_3 \delta)
	+ (q_1 - q_2) \exp(s_3 \xi) \exp(s_3 \xi)}
{\exp(s_1 \xi) \exp(s_3 \delta)
	- \exp(s_2 \xi) \exp(s_3 \delta)}\\
&= h(\xi) \,.
\end{align*}
%
\begin{align*}
(q_2 - q_3) \exp(s_1 (\xi + \delta)) &\geq
(q_2 - q_3) \exp(s_1 \xi) \exp(s_3 \delta)\\
(q_3 - q_1) \exp(s_2 (\xi + \delta)) &\geq
(q_3 - q_1) \exp(s_2 \xi) \exp(s_3 \delta)\\
(q_1 - q_2) \exp(s_3 (\xi + \delta)) &\geq
(q_1 - q_2) \exp(s_3 \xi) \exp(s_3 \xi)\\
\exp(s_1 (\xi + \delta)) &\leq \exp(s_1 \xi) \exp(s_3 \delta)\\
\exp(s_2 (\xi + \delta)) &\geq \exp(s_2 \xi) \exp(s_3 \delta)\\
\end{align*}
%
This shows that $h$ is strictly increasing.
As $h$ is continuous, we can conclude that it has exactly one root.
%

%
Therefore there is a bijection between  $\Theta$ and ${\cal Q}$
(defined in (\ref{eq:Theta}) and (\ref{eq:Q})) via the transformation $g$.
To transform a prior $\pi_q$ for $(q_1, q_2, q_3)$ to a prior
$\pi_\theta$ for $(\mu, \sigma, \xi)$,
we applied the transformation using the change of variables formula.
Alternatively, we could sample from $\pi_q$,
apply the inverse of $g$, which involves finding the root of $h$ numerically,
and then use kernel density estimation.
%


%%%%% ME APPROXIMATION OF GAMMA MARGINALS

In order to construct the prior $\pi^{\text{ME}}_q$
so as to be comparable, we chose its marginals
as an approximation of the marginals of $\pi^{\text{QD}}_q$.
We determined Gamma distributions
$F_1, F_2, F_3$ such that
%
\begin{align*}
\tilde{q}_1 &\mathrel{\dot\sim} F_1 \,,\\
\tilde{q}_1 + \tilde{q}_2 &\mathrel{\dot\sim} F_2 \,,\\
\tilde{q}_1 + \tilde{q}_2 + \tilde{q}_3 &\mathrel{\dot\sim}F_3 \,,
\end{align*}
%
using numerical minimisation of the Kullback–Leibler divergence.
Table~\ref{table:gamma_approx} shows that the approximation is good.
%
\begin{table*}
	\centering
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{@{}ccc@{}}
		\toprule[0.1em]
		&Median &$0.95$-quantile\\
		\midrule[0.1em]
		$\pi^{\text{QD}}_{q_1}$ &57.563 &74.172\\
		$\pi^{\text{ME}}_{q_1}$ &57.563 &74.172\\
		\midrule[0.05em]
		$\pi^{\text{QD}}_{q_2}$ &100.767 &136.380\\
		$\pi^{\text{ME}}_{q_2}$ &101.269 &135.133\\
		\midrule[0.05em]
		$\pi^{\text{QD}}_{q_3}$ &221.653 &267.691\\
		$\pi^{\text{ME}}_{q_3}$ &221.943 &267.080\\
		\bottomrule[0.1em]
	\end{tabular}
	\caption{Comparison of the marginals of $q_1, q_2, q_3$
		for pseudo-data simulation study}
	\label{table:gamma_approx}
\end{table*}


% MCMC details

\subsection{MCMC details}
\label{section:mcmc-tables}
%
From Table~\ref{table:pp-1} to Table~\ref{table:pp-2},
we show the results of the Metropolis algorithm
for the Poisson process simulation study,
and from Table~\ref{table:gamma-1} to Table~\ref{table:gamma-2},
we show the results for the pseudo-data simulation study.
%
\metroall{pp}{G}{Poisson process simulation study}
%
\metroall{gamma}{G}{pseudo-data simulation study}



% SAS xi

%
To illustrate the spike-and-slab shape of the prior, it can be reformulated as
%
\begin{align*}
	\pi_{\theta}^{\text{SAS}}(\mu, \sigma, \xi) &=
			\begin{cases}
			\alpha\pi_\theta(\mu, \sigma, \xi) & \quad \text{$\xi \neq 0 $} \\
			\pi_\theta(\mu, \sigma, 0) + (1 - \alpha)
				\pi_{\mu, \sigma}(\mu, \sigma) & \quad \text{$\xi = 0 $} \,. \\
		\end{cases}
\end{align*}
%